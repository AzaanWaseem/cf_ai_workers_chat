# Project Structure

```
cf_ai_workers_chat/
â”‚
â”œâ”€â”€ src/                          # Cloudflare Worker Backend
â”‚   â”œâ”€â”€ index.ts                  # Main Worker entry point
â”‚   â”‚                             # - Handles HTTP routing
â”‚   â”‚                             # - Manages CORS
â”‚   â”‚                             # - Creates/retrieves Agents
â”‚   â”‚
â”‚   â””â”€â”€ agent.ts                  # ChatAgent Durable Object
â”‚                                 # - Manages conversation state
â”‚                                 # - Calls Workers AI (Llama 3.3)
â”‚                                 # - Persists chat history
â”‚
â”œâ”€â”€ frontend/                     # Next.js Frontend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â””â”€â”€ chat/
â”‚   â”‚   â”‚       â””â”€â”€ route.ts      # API route (proxies to Worker)
â”‚   â”‚   â”œâ”€â”€ layout.tsx            # Root layout
â”‚   â”‚   â”œâ”€â”€ page.tsx              # Main chat page
â”‚   â”‚   â””â”€â”€ globals.css           # Global styles
â”‚   â”‚
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ chat-input.tsx        # Message input component
â”‚   â”‚   â”œâ”€â”€ chat-message.tsx      # Single message display
â”‚   â”‚   â”œâ”€â”€ chat-messages.tsx     # Messages list
â”‚   â”‚   â””â”€â”€ ui/                   # shadcn/ui components
â”‚   â”‚
â”‚   â”œâ”€â”€ types/
â”‚   â”‚   â””â”€â”€ chat.ts               # TypeScript interfaces
â”‚   â”‚
â”‚   â”œâ”€â”€ .env.local                # Environment variables
â”‚   â””â”€â”€ package.json              # Frontend dependencies
â”‚
â”œâ”€â”€ wrangler.toml                 # Cloudflare Workers config
â”‚                                 # - Durable Objects setup
â”‚                                 # - Workers AI binding
â”‚                                 # - Deployment settings
â”‚
â”œâ”€â”€ package.json                  # Backend dependencies
â”œâ”€â”€ tsconfig.json                 # TypeScript config
â”œâ”€â”€ README.md                     # Main documentation
â”œâ”€â”€ SETUP.md                      # Setup instructions
â””â”€â”€ quick-start.sh                # Quick setup script

```

## ğŸ—‚ï¸ Key Files Explained

### Backend (Cloudflare Worker)

**`src/index.ts`** - Entry Point
- Receives HTTP requests from frontend
- Handles CORS for cross-origin requests
- Routes `/api/chat` to appropriate Agent
- Creates unique Agent per userId
- Health check endpoint at `/`

**`src/agent.ts`** - ChatAgent Durable Object
- Extends Cloudflare's DurableObject class
- Manages per-user conversation state
- Stores messages in Durable Object storage
- Calls Workers AI (Llama 3.3) for responses
- Persists state across requests

**`wrangler.toml`** - Configuration
- Defines Durable Object bindings
- Configures Workers AI access
- Sets up migrations
- Deployment settings

### Frontend (Next.js)

**`app/page.tsx`** - Main Chat UI
- Chat interface with messages
- Input form for user messages
- Calls `/api/chat` endpoint

**`app/api/chat/route.ts`** - API Proxy
- Receives messages from frontend
- Forwards to Cloudflare Worker
- Returns AI responses

**`components/`** - UI Components
- Modular, reusable components
- Built with shadcn/ui and Tailwind

**`.env.local`** - Environment Config
- `NEXT_PUBLIC_WORKER_URL`: Backend URL
- Supports local and production URLs

## ğŸ”„ Request Flow

```
1. User types message in Frontend UI
        â†“
2. Frontend sends POST to /api/chat
        â†“
3. Next.js API route forwards to Worker
        â†“
4. Worker creates/retrieves Agent Durable Object
        â†“
5. Agent loads conversation history from storage
        â†“
6. Agent adds user message to history
        â†“
7. Agent calls Workers AI (Llama 3.3)
        â†“
8. Workers AI returns response
        â†“
9. Agent adds AI response to history
        â†“
10. Agent saves updated history to storage
        â†“
11. Response flows back through Worker â†’ Next.js â†’ Frontend
        â†“
12. Frontend displays AI message
```

## ğŸ”‘ Key Concepts

### Durable Objects (Agent State)
- Each user gets unique Agent instance
- State persists in Cloudflare's edge network
- Survives deployments and restarts
- Strong consistency guarantee

### Workers AI
- Runs Llama 3.3 70B model
- No GPU/infrastructure management needed
- Pay-per-request pricing
- Global edge network

### Conversation Memory
- Stored in `this.ctx.storage`
- Array of ChatMessage objects
- Includes system prompt + history
- Persists across sessions

## ğŸ“Š Data Flow

**Message Storage:**
```typescript
AgentState {
  messages: ChatMessage[]        // Full conversation
  userId: string                 // User identifier
  createdAt: string             // Timestamp
}
```

**ChatMessage:**
```typescript
{
  role: 'user' | 'assistant' | 'system'
  content: string
}
```

## ğŸ¯ Technology Stack

**Backend:**
- Cloudflare Workers (Serverless)
- Durable Objects (State)
- Workers AI (LLM)
- TypeScript

**Frontend:**
- Next.js 14+ (React Framework)
- Tailwind CSS (Styling)
- shadcn/ui (Components)
- TypeScript

## ğŸ“¦ Dependencies

**Backend:**
- `@cloudflare/workers-types` - Type definitions
- `wrangler` - CLI for deployment
- `typescript` - TypeScript compiler

**Frontend:**
- `next` - React framework
- `react` & `react-dom` - UI library
- `tailwindcss` - Utility-first CSS
- Various shadcn/ui packages

## ğŸš€ Deployment Targets

**Backend:** Cloudflare Workers
- Automatic edge deployment
- Global CDN distribution
- `*.workers.dev` subdomain

**Frontend:** Vercel (Recommended)
- Automatic Next.js optimization
- Edge functions support
- Custom domain support

Alternative: Cloudflare Pages, Netlify, or self-host

---

For setup instructions, see **SETUP.md**
For detailed documentation, see **README.md**
